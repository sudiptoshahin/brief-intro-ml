{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Article list\n",
    "* machine learning / ai\n",
    "* how machine learning works\n",
    "* machine learning algorithms\n",
    "    * Supervised -> linear / logistic regression, svm, Decision trees, Random forests, k-NN, Neural networks, Naive bayes - explain with 1/2 problems\n",
    "    * Unsupervised -> K-Means Clustering, Hierarchical Clustering, Principal Component Analysis (PCA), t-Distributed Stochastic Neighbor Embedding (t-SNE), Gaussian Mixture Models (GMM), Autoencoders, Self-Organizing Maps (SOM), DBSCAN (Density-Based Spatial Clustering of Applications with Noise)\n",
    "    * Semi-Supervised -> Self-training, Co-training, Generative Models (Generative Adversarial Networks)\n",
    "    * Reinforcement -> Q-Learning, Deep Q-Networks (DQN), Policy Gradient Methods, Actor-Critic Methods, Deep Deterministic Policy Gradient (DDPG), Proximal Policy Optimization (PPO)\n",
    "    * Ensemble -> Bagging (Bootstrap Aggregating), Boosting (e.g., AdaBoost, Gradient Boosting), Stacking, Voting Classifiers\n",
    "    * Deep Learning -> CNN, RNN, LSTM, Gated Recurrent Units (GRU), Transformer Models, Capsule Networks, Variational Autoencoders (VAE), Generative Adversarial Networks (GAN)\n",
    "    * Anomaly Detection -> Isolation Forest, One-Class SVM, Autoencoders, Local Outlier Factor (LOF)\n",
    "    * Dimensionality Reduction -> Principal Component Analysis (PCA), Linear Discriminant Analysis (LDA), t-Distributed Stochastic Neighbor Embedding (t-SNE), Autoencoders\n",
    "    * Feature Selection -> Recursive Feature Elimination (RFE), Feature Importance (e.g., from tree-based models), Lasso Regression\n",
    "* AI algorithms\n",
    "\n",
    "* research topic\n",
    "    * how ai can reduced improve the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vision input output\n",
    "\n",
    "raw image -> numerical encoding -> model -> output -> predicted output <br>\n",
    "\n",
    "* input shapes\n",
    "```[batch_size, width, height, color_channel]``` ex: [None, 224, 224, 3], [32, 224, 224, 3]\n",
    "\n",
    "batch_size is problem specific depending on hardware\n",
    "\n",
    "* output shape: number of class [n, ....]\n",
    "\n",
    "Different input shapes (for different frameworks):\n",
    "1. shape -> [None, 28, 28, 1] (NHWC)\n",
    "2. shape -> [None, 1, 28, 28] (NCHW)\n",
    "\n",
    "##### Path to build\n",
    "* Get the data ready (convert to tensors)\n",
    "* Build or pick a model - Pick a loss function, Build a training loop\n",
    "* Fit the model to the data and make prediction\n",
    "* Evaluate the model\n",
    "* Improve through experimentation\n",
    "* Save and reload the trained model\n",
    "\n",
    "#### CNN\n",
    "- Convolutional layer - 'requires input data, filter (feature detector/kernel), featuremap'\n",
    "`nb`: we have a feature detector, also known as a kernel or a filter, which will move across the receptive fields of the image, checking if the feature is present. This process is known as a convolution.\n",
    "- Pooling layer\n",
    "- Fully-connected layer\n",
    "\n",
    "#### Libs\n",
    "* `torchvision.datasets` - get datasets and data loading function for computer vision here\n",
    "* `torchvision.models` - pytorch pre-trained modesl\n",
    "* `torchvision.transforms` - functions  for manipulating vision data to be suitable for use with\n",
    "* `torch.utils.data.Dataset` - Base dataset class for pytorch\n",
    "* `torch.utils.data.DataLoader` - create python iterable over a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipykernel\n",
    "print(ipykernel.__version__)\n",
    "print(\"5dc3a68c-e34e-4080-9c3e-2a532b2ccb4d\")\n",
    "print(ipykernel.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Device agnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n",
    "import torch\n",
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Getting dataset\n",
    "`FashionMNIST`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=torchvision.transforms.ToTensor(),\n",
    "    target_transform=None\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = train_data[0]\n",
    "\n",
    "type(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_data.classes\n",
    "class_to_idx = train_data.class_to_idx\n",
    "class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image, label = train_data[0]\n",
    "print(f'Image size: {image.shape}')\n",
    "\n",
    "# Image.open(image.permute(1, 2, 0)).show()\n",
    "# torch.Tensor.toPILImage(image)\n",
    "\n",
    "plt.imshow(image.permute(1,2,0), cmap='gray')\n",
    "plt.title(label=class_names[label])\n",
    "plt.axis(False)\n",
    "\n",
    "# _image = image.numpy()\n",
    "\n",
    "# plt.imshow(_image)\n",
    "# plt.title(label=class_names[label])\n",
    "# plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot more\n",
    "torch.manual_seed(42)\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "rows, cols = 4, 5\n",
    "for i in range(1, rows*cols+1):\n",
    "    random_idx = torch.randint(0, len(train_data), size=(1, )).item()\n",
    "    # print(random_idx)\n",
    "    img, label = train_data[random_idx]\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.imshow(img.squeeze(), cmap='gray')\n",
    "    plt.title(class_names[label])\n",
    "    plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. prepare dataloader\n",
    "\n",
    "Now dataset is in form of pytorch datasets.\n",
    "DataLoader turns dataset into a python iterable or turn into mini-batches\n",
    "\n",
    "1. its more computationally efficient as in computing hardware\n",
    "2. it gives our neural network more chanaces to update its gradients per epoch\n",
    "\n",
    "dataloader: https://pytorch.org/docs/stable/data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# setup batch size hyperparameter\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# turn datasets intor iterables\n",
    "train_dataloader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(['a', 'b', 'c', 'd']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Dataloader: {train_dataloader, test_dataloader}')\n",
    "print(f'Length: train - {len(train_dataloader)} batches of {BATCH_SIZE}')\n",
    "print(f'Lenght: test - {len(test_dataloader)} batches of {BATCH_SIZE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
    "print(train_features_batch.shape, train_labels_batch.shape)\n",
    "# show a sample from dataloader\n",
    "torch.manual_seed(42)\n",
    "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
    "img, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
    "plt.imshow(img.squeeze(), cmap='gray')\n",
    "plt.title(class_names[label])\n",
    "plt.axis(False)\n",
    "print(f'Image size: {img.shape}')\n",
    "print(f'Label: {label}, label shape: {label.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_features_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create model0\n",
    "\n",
    "build a baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_num = torch.randn(32, 1, 20, 30)\n",
    "\n",
    "flatte_layer = nn.Flatten(end_dim=-1)\n",
    "output = flatte_layer(rnd_num)\n",
    "\n",
    "# output.dim\n",
    "print(f'Output shape: {output.shape}')\n",
    "\n",
    "batch_size = output.shape[0]\n",
    "data_size = output.shape[1]\n",
    "\n",
    "batch = output[:, None, None]\n",
    "data = output[None, :, :]\n",
    "\n",
    "batch.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten layer\n",
    "flatten_model = nn.Flatten()\n",
    "\n",
    "# get a single sample\n",
    "x = train_features_batch[0]\n",
    "\n",
    "# flatten the sample\n",
    "output = flatten_model(x)\n",
    "\n",
    "print(f'Shape before flattening: {x.shape}')\n",
    "print(f'Shape after flattening: {output.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(32, 1, 5, 5)\n",
    "\n",
    "flatten = nn.Flatten(end_dim=-1) \n",
    "output1 = flatten(input)\n",
    "output2 = flatten(output1)\n",
    "output2.size()\n",
    "# print(input)\n",
    "# output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class FashionMNISTModelV0(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int,  output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# setup model with input parameters\n",
    "model_0 = FashionMNISTModelV0(\n",
    "    input_shape=28*28, # or 784\n",
    "    hidden_units=10, # how many units in the hidden layer\n",
    "    output_shape=len(class_names) # one for every class\n",
    ").to(device)\n",
    "\n",
    "model_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_x = torch.rand([1, 1, 28, 28]).to(device)\n",
    "\n",
    "model_0(dummy_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Setup loss, optimizer and evaluation metrics\n",
    "\n",
    "* Loss function - `nn.CrossEntropyLoss()`\n",
    "* Optimizer - `torch.optim.SGD()`\n",
    "* Evaluation metric - since we are working on classification problem, lets use accuracy as our evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "urls = 'https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py'\n",
    "\n",
    "# download helper function\n",
    "if Path('helper_functions.py').is_file():\n",
    "    print('helper_functions.py already exists.')\n",
    "else:\n",
    "    print('Downloading helper_function.py')\n",
    "    request = requests.get(url=urls)\n",
    "    with open('helper_functions.py', 'wb') as file:\n",
    "        file.write(request.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import accuracy metric\n",
    "from helper_functions import accuracy_fn\n",
    "\n",
    "# setup loss funtion and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Creating a function to time our experiments\n",
    "\n",
    "ml is experimental.\n",
    "\n",
    "2 main things often want to track are:\n",
    "1. Models performance (loss and accuracy value)\n",
    "2. How fast it runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "def print_train_time(start: float, end: float, device: torch.device = None):\n",
    "    \"\"\" difference between start and end time \"\"\"\n",
    "    total_time = end - start\n",
    "    print(f'Train time on {device}: {total_time:.3f} seconds')\n",
    "    return total_time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timer()\n",
    "\n",
    "end_time = timer()\n",
    "print_train_time(start=start_time, end=end_time, device='cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a training loop and trainning a model on batches of data\n",
    "The optimizer will update a models parameters once per batch rather than once per epoch\n",
    "\n",
    "## Creating a training loop and training a model on batches of data\n",
    "1. Loop through epochs\n",
    "2. Loop through training batches, perform training steps, calculate the train loss *per batch*\n",
    "3. Loop through testing batches, perform testing steps, calculate the test loss *per batch*\n",
    "4. print out whats happening\n",
    "5. Time it all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tqdm for progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# set the seed and start the timers\n",
    "torch.manual_seed(42)\n",
    "train_time_start_on_cpu = timer()\n",
    "\n",
    "# set the number of epochs (we'll keep this small for faster training time)\n",
    "epochs = 3\n",
    "\n",
    "# create the training and test loop\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f'Epoch: {epoch}\\n-------------')\n",
    "    ### training\n",
    "    train_loss = 0\n",
    "\n",
    "    # add a loop through the training batches\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        model_0.train()\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # 1. Forward pass\n",
    "        y_pred = model_0(X)\n",
    "\n",
    "        # 2. Calculate the loss (per batch)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss # accumulate train loss\n",
    "\n",
    "        # 3. optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. loss backward\n",
    "        loss.backward()\n",
    "\n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 400 == 0:\n",
    "            print(f'Looked at {batch * len(X)}/{len(train_dataloader.dataset)}')\n",
    "\n",
    "# divide total train loss by lenght of train dataloader\n",
    "train_loss /= len(train_dataloader)\n",
    "\n",
    "\n",
    "### Testing loop\n",
    "test_loss, test_acc = 0, 0\n",
    "model_0.eval()\n",
    "with torch.inference_mode():\n",
    "    for X_test, y_test in test_dataloader:\n",
    "        # 1. forward pass\n",
    "        # test_pred_logits = model_0(X_test)\n",
    "        X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "        test_pred = model_0(X_test)\n",
    "\n",
    "        # 2. Calculate loss (accumulatively)\n",
    "        test_loss += loss_fn(test_pred, y_test)\n",
    "\n",
    "        # 3. Calculate accuracy\n",
    "        test_acc += accuracy_fn(y_true=y_test, y_pred=test_pred.argmax(dim=1))\n",
    "\n",
    "    # Calculate the test loss average per batch\n",
    "    test_loss /= len(test_dataloader)\n",
    "\n",
    "    # Calculate the test acc average per batch\n",
    "    test_acc /= len(test_dataloader)\n",
    "\n",
    "# Prints whats happen\n",
    "print(f'\\n Train loss: {train_loss:.4f} | Test Loss: {test_loss:.4f}, Test acc: {test_acc:.4f}')\n",
    "\n",
    "train_time_end_on_cpu = timer()\n",
    "\n",
    "total_train_time_model_0 = print_train_time(start=train_time_start_on_cpu,\n",
    "                                            end=train_time_end_on_cpu,\n",
    "                                            device=str(next(model_0.parameters()).device))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions and model_0 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "def  eval_model(model: torch.nn.Module,\n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               accuracy_fn,\n",
    "               device):\n",
    "    \"\"\" Returns a dictionary containing the results of model predicting on data_loader \"\"\"\n",
    "    loss, acc = 0, 0\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            _X, _y = X.to(device), y.to(device)\n",
    "            # make predictions\n",
    "            # print(next(iter(X)).device)\n",
    "            y_pred = model(_X)\n",
    "\n",
    "            # Accumulate the loss and acc values per batch\n",
    "            loss += loss_fn(y_pred, _y)\n",
    "            acc += accuracy_fn(y_true=_y, y_pred=y_pred.argmax(dim=1))\n",
    "        \n",
    "        # Scale loss and acc to fund the average loss/acc per batch\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "    return {\"model_name\": model.__class__.__name__,\n",
    "            \"model_loss\": loss.item(),\n",
    "            \"model_acc\": acc}\n",
    "\n",
    "\n",
    "# Calculate model 0 results on test datasets\n",
    "model_0_results = eval_model(model=model_0, \n",
    "                            data_loader=test_dataloader, \n",
    "                            loss_fn=loss_fn,\n",
    "                            accuracy_fn=accuracy_fn,\n",
    "                            device=device)\n",
    "\n",
    "model_0_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### building model with non-linearrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a model with non-linear and linear layers\n",
    "\n",
    "class FashionMNISTModelV1(nn.Module):\n",
    "    def __init__(self, input_shape: int,\n",
    "                hidden_units: int,\n",
    "                output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(), # input into single vector\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(model_0.parameters()).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an instance model\n",
    "torch.manual_seed(42)\n",
    "model_1 = FashionMNISTModelV1(input_shape=784,\n",
    "                              hidden_units=10,\n",
    "                              output_shape=len(class_names)).to(device) # send the gpu if available\n",
    "\n",
    "\n",
    "next(model_1.parameters()).device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 Setup Loss, Optimizer and Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import accuracy_fn\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(params=model_1.parameters(), lr=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functionizing training and evaluation / testing loop\n",
    "* training loop - train_step()\n",
    "* testing_loop - test_step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module, \n",
    "               data_loader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               accuracy_fn,\n",
    "               device: torch.device = device):\n",
    "    # Traning\n",
    "    \"\"\"Performs a training with model trying to learn on data_loader\"\"\"\n",
    "    train_loss, train_acc = 0, 0\n",
    "    model.to(device=device)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(data_loader):\n",
    "        # 1. forward pass\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_pred = model(X)\n",
    "        \n",
    "        # 2. calculate loss & accuracy(per batch)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        train_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
    "        \n",
    "        # 3. optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 4. loss backward\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. optimizer step (update the models parameters once *per batch*)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print out whats happen\n",
    "        # if batch % 400 == 0:\n",
    "        #     print(f'Looked at {batch * len(X)}/{len(data_loader.dataset)} samples.')\n",
    "            \n",
    "    # devide the total train loss and accuracy of data_loader\n",
    "    train_loss /= len(data_loader)\n",
    "    train_acc /= len(data_loader)\n",
    "    print(f'Train loss: {train_loss:.5f} | Train acc: {train_acc:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model: torch.nn.Module,\n",
    "              data_loader: torch.utils.data.DataLoader,\n",
    "              loss_fn: torch.nn.Module, \n",
    "              accuracy_fn,\n",
    "              device: torch.device = device):\n",
    "    \n",
    "    test_loss, test_acc = 0, 0\n",
    "    \n",
    "    # model in eval mode\n",
    "    model.eval()\n",
    "    \n",
    "    # turn on inference mode context manager\n",
    "    with torch.inference_mode():\n",
    "        for X_test, y_test in data_loader:    \n",
    "            # send the data to the target device\n",
    "            X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "            # 1. forward pass (output raw logits)\n",
    "            test_pred = model(X_test)\n",
    "            # 2. calculate the loss & accuracy\n",
    "            loss = loss_fn(test_pred, y_test)\n",
    "            test_loss += loss\n",
    "            test_acc += accuracy_fn(y_true=y_test, y_pred=test_pred.argmax(dim=1))\n",
    "        \n",
    "        # adjust matrics and printout\n",
    "        test_loss /= len(data_loader)\n",
    "        test_acc /= len(data_loader)\n",
    "        print(f'Test loss: {test_loss:.5f} | Test acc: {test_acc:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# measure time\n",
    "from timeit import default_timer as Timer\n",
    "train_time_start_on_cpu = timer()\n",
    "\n",
    "# set epochs\n",
    "epochs = 3\n",
    "\n",
    "# create a optimization and evaluation loop using train_step() and test_step()\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f'-----------Epoch: {epoch}---------\\n')\n",
    "    train_step(\n",
    "        model=model_1,\n",
    "        data_loader=train_dataloader,\n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    test_step(\n",
    "        model=model_1,\n",
    "        data_loader=test_dataloader,\n",
    "        loss_fn=loss_fn,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "train_time_end_on_cpu = timer()\n",
    "total_train_time_model_1 = print_train_time(\n",
    "    start=train_time_start_on_cpu, \n",
    "    end=train_time_end_on_cpu,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_train_time_model_0)\n",
    "print(total_train_time_model_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model_1 results dictionary\n",
    "model_1_results = eval_model(model=model_1,\n",
    "                            data_loader=test_dataloader,\n",
    "                            loss_fn=loss_fn,\n",
    "                            accuracy_fn=accuracy_fn,\n",
    "                            device=device)\n",
    "\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2: building convolutional neural network (cnn)\n",
    "\n",
    "* CNN's are also known ConvNets.\n",
    "* CNN's are known for their capabilities to find patterns in visual data\n",
    "\n",
    "https://poloclub.github.io/cnn-explainer/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a convolutional neural network \n",
    "class FashionMNISTModelV2(nn.Module):\n",
    "    \"\"\"\n",
    "    Model architecture copying TinyVGG from: \n",
    "    https://poloclub.github.io/cnn-explainer/\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape, \n",
    "                      out_channels=hidden_units, \n",
    "                      kernel_size=3, # how big is the square that's going over the image?\n",
    "                      stride=1, # default\n",
    "                      padding=1),# options = \"valid\" (no padding) or \"same\" (output has same shape as input) or int for specific number \n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units, \n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2,\n",
    "                         stride=2) # default stride value is same as kernel_size\n",
    "        )\n",
    "        self.block_2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),    \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            # Where did this in_features shape come from? \n",
    "            # It's because each layer of our network compresses and changes the shape of our inputs data.\n",
    "            nn.Linear(in_features=hidden_units*7*7, \n",
    "                      out_features=output_shape)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.block_1(x)\n",
    "        # print(x.shape)\n",
    "        x = self.block_2(x)\n",
    "        # print(x.shape)\n",
    "        x = self.classifier(x)\n",
    "        # print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "# input shape is based on image color channels\n",
    "model_2 = FashionMNISTModelV2(input_shape=1,\n",
    "                              hidden_units=10,\n",
    "                              output_shape=len(class_names)).to(device)\n",
    "\n",
    "model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(model_2.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stepping through Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# create a batch of images\n",
    "images = torch.randn(size=(32, 3, 64, 64))\n",
    "test_image = images[0]\n",
    "\n",
    "print(f'Image batch shape: {images.shape}')\n",
    "print(f'Single image shape: {test_image.shape}')\n",
    "print(f'Test image\\n: {test_image}')\n",
    "\n",
    "test_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create single conv2d layer\n",
    "conv_layer = nn.Conv2d(in_channels=3,\n",
    "                       out_channels=64,\n",
    "                       kernel_size=(2, 2),\n",
    "                       stride=1,\n",
    "                       padding=0)\n",
    "\n",
    "# pass the data through the convolutional layer\n",
    "conv_output = conv_layer(test_image.unsqueeze(0))\n",
    "conv_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image.unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### stepping through MaxPool2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Test image original shape: {test_image.shape}')\n",
    "print(f'Test image with unsqueeze dimension: {test_image.unsqueeze(0).shape}')\n",
    "\n",
    "# create a sample nn.MaxPool2d layer\n",
    "max_pool_layer = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "# pass through just the conv layer\n",
    "test_image_thorugh_conv = conv_layer(test_image.unsqueeze(dim=0))\n",
    "print(f'Shape after going through conv_layer(): {test_image_thorugh_conv.shape}')\n",
    "\n",
    "# pass data through the max pool layer\n",
    "test_image_through_conv_and_max_pool = max_pool_layer(test_image_thorugh_conv)\n",
    "print(f'Shape after going through conv_layer and max_pool_layer(): {test_image_through_conv_and_max_pool.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "# create random tensor with a similar number of dimension\n",
    "random_tensor = torch.randn(size=(1, 1, 2, 2))\n",
    "\n",
    "# create a max pool layer\n",
    "max_pool_layer = nn.MaxPool2d(kernel_size=2)\n",
    "8\n",
    "# pass the random tensor through the max pool layer\n",
    "max_pool_tensor = max_pool_layer(random_tensor)\n",
    "\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "convert_to_tensor = transforms.ToTensor()\n",
    "\n",
    "image_path = os.path.join(os.pardir, 'images', '4.jpg')\n",
    "img = Image.open(image_path)\n",
    "\n",
    "img_tensor = convert_to_tensor(img)\n",
    "\n",
    "# plt.imshow(img_tensor.numpy())\n",
    "print(f'Imamge tensor original shape: {img_tensor.shape}')\n",
    "print(f'Image tensor shape after squeeze: {img_tensor.permute(1, 2, 0).shape}')\n",
    "\n",
    "plt.imshow(img_tensor.permute(1, 2, 0))\n",
    "output_conv = conv_layer(img_tensor)\n",
    "\n",
    "type(output_conv)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image.squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_image_tensor = torch.randn(size=(1, 28, 28))\n",
    "\n",
    "model_2(rand_image_tensor.unsqueeze(0).to(device)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup a loss function and optimizer for model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup loss function / eval metrics/optimizer\n",
    "from helper_functions import accuracy_fn\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.SGD(params=model_2.parameters(), lr=0.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and testing ```model_2``` with traning and testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "# Measure time\n",
    "from timeit import default_timer as timer\n",
    "train_time_start_model_2 = timer()\n",
    "\n",
    "# Train and test model \n",
    "epochs = 3\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    print(f\"Epoch: {epoch}\\n---------\")\n",
    "    train_step(data_loader=train_dataloader, \n",
    "        model=model_2, \n",
    "        loss_fn=loss_fn,\n",
    "        optimizer=optimizer,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device\n",
    "    )\n",
    "    test_step(data_loader=test_dataloader,\n",
    "        model=model_2,\n",
    "        loss_fn=loss_fn,\n",
    "        accuracy_fn=accuracy_fn,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "train_time_end_model_2 = timer()\n",
    "total_train_time_model_2 = print_train_time(start=train_time_start_model_2,\n",
    "                                           end=train_time_end_model_2,\n",
    "                                           device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "epochs = 3\n",
    "\n",
    "train_loss, train_acc = 0, 0\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    # train\n",
    "    model_2.train()\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # 1. forward pass\n",
    "        y_pred = model_2(X)\n",
    "\n",
    "        # 2. calculate loss\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        train_loss += loss\n",
    "        # print(f'y: {y.shape} | y-pred: {y_pred.shape}')\n",
    "        train_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))\n",
    "\n",
    "        # 3. optimizer\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. loss backward\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. optimizer step\n",
    "        optimizer.step()\n",
    "\n",
    "    # loss and accuracy for each epochs\n",
    "    train_loss /= len(train_dataloader)\n",
    "    train_acc /= len(train_dataloader)\n",
    "    print(f'Train loss: {train_loss} | Train accuracy: {train_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model_2 results\n",
    "model_2_results = eval_model(model=model_2,\n",
    "                            data_loader=test_dataloader,\n",
    "                            loss_fn=loss_fn,\n",
    "                            accuracy_fn=accuracy_fn,\n",
    "                            device=device)\n",
    "\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare model results and training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "compare_results = pd.DataFrame([\n",
    "    model_0_results,\n",
    "    model_1_results,\n",
    "    model_2_results\n",
    "])\n",
    "\n",
    "compare_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add training time to results comparison\n",
    "compare_results['training_time'] = [\n",
    "    total_train_time_model_0,\n",
    "    total_train_time_model_1,\n",
    "    total_train_time_model_2\n",
    "]\n",
    "\n",
    "compare_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize our model results\n",
    "compare_results.set_index('model_name')['model_acc'].plot(kind='barh')\n",
    "plt.xlabel('accuracy (%)')\n",
    "plt.ylabel('model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make and evaluate random predicitons with best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model: torch.nn.Module,\n",
    "                     data: list,\n",
    "                     device: torch.device = device):\n",
    "    pred_probs = []\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        for idx, sample in enumerate(data):\n",
    "            # sample (1, 28, 28)\n",
    "            # prepare the sample data (add a batch dimension and pass it to the target device)\n",
    "            sample = torch.unsqueeze(sample, dim=0).to(device)\n",
    "            # sample (1, 1, 28, 28)\n",
    "\n",
    "            # forward pass (model outputs raw logits)\n",
    "            pred_logit = model(sample)\n",
    "            # ([1, 10])\n",
    "\n",
    "            # get prediction probability (logit -> prediction probability)\n",
    "            pred_prob = torch.softmax(pred_logit.squeeze(), dim=0)\n",
    "            # ([10])\n",
    "            # get pred_prob off the GPU for further calculations\n",
    "            pred_probs.append(pred_prob.cpu())\n",
    "    \n",
    "    # stack the pred_probs to turn list into a tensor\n",
    "    return torch.stack(pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = test_data[0][:10]\n",
    "\n",
    "img.shape, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "mylist = [\"apple\", \"banana\", \"cherry\", \"two\", \"three\", 'mango']\n",
    "\n",
    "print(random.sample(mylist, k=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "test_samples = []\n",
    "test_labels = []\n",
    "\n",
    "for sample, label in random.sample(list(test_data), k=9):\n",
    "    test_samples.append(sample)\n",
    "    test_labels.append(label)\n",
    "\n",
    "# view the samples shape\n",
    "test_samples[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_samples[0].squeeze(), cmap='gray')\n",
    "plt.title(class_names[test_labels[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "pred_probs = make_predictions(model=model_2,\n",
    "                            data=test_samples)\n",
    "\n",
    "# view first 2 prediction probabilities\n",
    "pred_probs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert prediction probabilities to labels\n",
    "pred_classes = pred_probs.argmax(dim=1)\n",
    "print(f'Predictions:\\n {pred_classes}')\n",
    "print(f'Test labels: \\n{test_labels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT predictions\n",
    "plt.figure(figsize=(9, 9))\n",
    "n_rows = 3\n",
    "n_cols = 3\n",
    "for i, sample in enumerate(test_samples):\n",
    "    # create subplot\n",
    "    plt.subplot(n_rows, n_cols, i+1)\n",
    "    \n",
    "    # plot the target image\n",
    "    plt.imshow(sample.squeeze(), cmap='gray')\n",
    "\n",
    "    # find the prediction (in text form, e.g 'sandle')\n",
    "    pred_label = class_names[pred_classes[i]]\n",
    "\n",
    "    # get the truth label(in text form)\n",
    "    truth_label = class_names[test_labels[i]]\n",
    "\n",
    "    # create a title for the plot\n",
    "    title_text = f'Pred: {pred_label} | Truth: {truth_label}'\n",
    "\n",
    "    # check for equality between pred an truth and change color of title text\n",
    "    if pred_label == truth_label:\n",
    "        plt.title(title_text, fontsize=10, c='g') # green text if prediction is same as truth\n",
    "    else:\n",
    "        plt.title(title_text, fontsize=10, c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making a confusion matrix for further prediction evaluation\n",
    "\n",
    "1. Make predictions with our trained model on the test dataset\n",
    "2. Make a confusion matrix `torchmetrics.ConfusionMatrix`\n",
    "3. Plot the confusion matrix using `mlxtend.plotting.plot_confision_matrix()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tqdm.auto\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 1. make predictions with trained model\n",
    "y_preds = []\n",
    "model_2.eval()\n",
    "with torch.inference_mode():\n",
    "    for X, y in tqdm(test_dataloader, desc='Making predictions....'):\n",
    "        # send the data and targets to the targeted device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        # Do the forward pass\n",
    "        y_logits = model_2(X)\n",
    "        # turn predictions from logits -> prediction probabilities -> prediction labels\n",
    "        y_pred = torch.softmax(y_logits.squeeze(), dim=0).argmax(dim=1)\n",
    "        # put prediction on CPU for evaluations \n",
    "        y_preds.append(y_pred.cpu())\n",
    "    \n",
    "    # concatenate list of predictions into a tensor\n",
    "    print(y_preds)\n",
    "    y_pred_tensor = torch.cat(y_preds)\n",
    "    y_pred_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if required packages are installed and if not, install them\n",
    "try:\n",
    "    import torchmetrics, mlxtend\n",
    "    print(f'mlxtend version: {mlxtend.__version__}')\n",
    "    assert int(mlxtend.__version__.split('.')[1]) > 20, 'mlxtend versi should be 0.19.0 or higher'\n",
    "except:\n",
    "    print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert int(mlxtend.__version__.split('.')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert int(mlxtend.__version__.split('.')[1]) > 30, 'mlxtend versi should be 0.19.0 or higher'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 19:15:00"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dreamflow-new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
